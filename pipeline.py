# -*- coding: utf-8 -*-
"""pipeline.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hfK0BCyWGqfu_wDMxfTM8F5gImgf2zJW
"""

import os
import numpy as np
import matplotlib
matplotlib.use("Pdf") 

import matplotlib.pyplot as plt
import glob
os.environ["GOOGLE_APPLICATION_CREDENTIALS"]="/home/pi/FY/cred/direct-outlet-274310-3418964237b1.json"

from PIL import Image
path_pre="/home/pi/FY/plot"
import os,wave
files=glob.glob(path_pre)
print("resizing the images to 150x150 ")
for filename in glob.glob(os.path.join(path_pre, '*.png')):
    #print(filename)

    path_resize= filename
    im = Image.open(path_resize)
    newsize = (150, 150)
    im1 = im.resize(newsize)
    im1 = im1.save("/home/pi/FY/plot/resized.png")

import base64
import json
img_filename = '/home/pi/FY/plot/resized.png'
json_filename = '/home/pi/FY/plot/bigb.json'

instances = []
with open(img_filename, 'rb') as img_file :
    img_str = base64.b64encode(img_file.read())
    img_str2 = img_str.decode()
    #print(str(img_str2))
    #instances.append(json_img)
    json_img = {"b64": str(img_str2)}
    #print(type(json_img['bytes']['b64']))
with open(json_filename, 'w') as outfile:
    json.dump(json_img, outfile)
request_body = {"bytes": json_img}
print("Converting the Image into base 64 format!")

import googleapiclient.discovery

def predict_json(project, region, model, instances, version=None):
    """Send json data to a deployed model for prediction.

    Args:
        project (str): project where the Cloud ML Engine Model is deployed.
        model (str): model name.
        instances ([Mapping[str: Any]]): Keys should be the names of Tensors
            your deployed model expects as inputs. Values should be datatypes
            convertible to Tensors, or (potentially nested) lists of datatypes
            convertible to tensors.
        version: str, version of the model to target.
    Returns:
        Mapping[str: any]: dictionary of prediction results defined by the
            model.
    """
    # Create the ML Engine service object.
    # To authenticate set the environment variable
    # GOOGLE_APPLICATION_CREDENTIALS=<path_to_service_account_file>
    service = googleapiclient.discovery.build('ml', 'v1')
    name = 'projects/{}/models/{}'.format(project, model)

    if version is not None:
        name += '/versions/{}'.format(version)

    response = service.projects().predict(
        name=name,
        body={'instances': instances}
    ).execute()

    if 'error' in response:
        raise RuntimeError(response['error'])

    return response['predictions']

print("Serving the converted json file to deployed CNN model on cloud")
output = (predict_json('direct-outlet-274310','asia-northeast1','heartrisk2',request_body,'hertriskv2'))
outputz = (output[0])
x = outputz["dense_5"]
print("The prediction from the model is",x)
#print(type(x))
x=((x[0]))
if (x < 0):
    print("The sample shows abnormal sounds , Further check-up is neccessary!")
else:
    print("The sample is negative , your heart is fine !")
